{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a0b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:52.681142Z",
     "iopub.status.busy": "2025-02-17T12:28:52.680805Z",
     "iopub.status.idle": "2025-02-17T12:28:55.273965Z",
     "shell.execute_reply": "2025-02-17T12:28:55.272094Z"
    },
    "papermill": {
     "duration": 2.607715,
     "end_time": "2025-02-17T12:28:55.276022",
     "exception": false,
     "start_time": "2025-02-17T12:28:52.668307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf944c9",
   "metadata": {
    "papermill": {
     "duration": 0.009496,
     "end_time": "2025-02-17T12:28:55.296402",
     "exception": false,
     "start_time": "2025-02-17T12:28:55.286906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Semantic Matrix Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b70b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:55.316485Z",
     "iopub.status.busy": "2025-02-17T12:28:55.315988Z",
     "iopub.status.idle": "2025-02-17T12:28:55.368174Z",
     "shell.execute_reply": "2025-02-17T12:28:55.367174Z"
    },
    "papermill": {
     "duration": 0.064215,
     "end_time": "2025-02-17T12:28:55.369900",
     "exception": false,
     "start_time": "2025-02-17T12:28:55.305685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('/kaggle/input/movielens-1m/movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46777c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:55.390201Z",
     "iopub.status.busy": "2025-02-17T12:28:55.389882Z",
     "iopub.status.idle": "2025-02-17T12:28:55.936571Z",
     "shell.execute_reply": "2025-02-17T12:28:55.935290Z"
    },
    "papermill": {
     "duration": 0.55956,
     "end_time": "2025-02-17T12:28:55.938883",
     "exception": false,
     "start_time": "2025-02-17T12:28:55.379323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('/kaggle/input/movielens-1m/ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f77657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:55.973289Z",
     "iopub.status.busy": "2025-02-17T12:28:55.972741Z",
     "iopub.status.idle": "2025-02-17T12:28:56.020158Z",
     "shell.execute_reply": "2025-02-17T12:28:56.018698Z"
    },
    "papermill": {
     "duration": 0.071985,
     "end_time": "2025-02-17T12:28:56.022471",
     "exception": false,
     "start_time": "2025-02-17T12:28:55.950486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_movie_ids = ratings['movieId'].unique()\n",
    "filtered_movies = movies[movies['movieId'].isin(ratings_movie_ids)]\n",
    "filtered_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37abe201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.053230Z",
     "iopub.status.busy": "2025-02-17T12:28:56.052881Z",
     "iopub.status.idle": "2025-02-17T12:28:56.060475Z",
     "shell.execute_reply": "2025-02-17T12:28:56.059340Z"
    },
    "papermill": {
     "duration": 0.020695,
     "end_time": "2025-02-17T12:28:56.062186",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.041491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_movies['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35786a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.085191Z",
     "iopub.status.busy": "2025-02-17T12:28:56.084661Z",
     "iopub.status.idle": "2025-02-17T12:28:56.093885Z",
     "shell.execute_reply": "2025-02-17T12:28:56.092553Z"
    },
    "papermill": {
     "duration": 0.024011,
     "end_time": "2025-02-17T12:28:56.096481",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.072470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_id_to_index = {movie_id: idx + 1 for idx, movie_id in enumerate(filtered_movies['movieId'])}\n",
    "len(movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df83fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.123853Z",
     "iopub.status.busy": "2025-02-17T12:28:56.123477Z",
     "iopub.status.idle": "2025-02-17T12:28:56.140509Z",
     "shell.execute_reply": "2025-02-17T12:28:56.139120Z"
    },
    "papermill": {
     "duration": 0.033306,
     "end_time": "2025-02-17T12:28:56.142196",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.108890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_movies['movieId'] = filtered_movies['movieId'].copy().map(movie_id_to_index)\n",
    "filtered_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee005d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.164537Z",
     "iopub.status.busy": "2025-02-17T12:28:56.164123Z",
     "iopub.status.idle": "2025-02-17T12:28:56.170201Z",
     "shell.execute_reply": "2025-02-17T12:28:56.169024Z"
    },
    "papermill": {
     "duration": 0.01904,
     "end_time": "2025-02-17T12:28:56.171949",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.152909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_movie_id = filtered_movies['movieId'].max()\n",
    "\n",
    "print(\"Maximum movieId in movies dataframe:\", max_movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425c1ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.193979Z",
     "iopub.status.busy": "2025-02-17T12:28:56.193602Z",
     "iopub.status.idle": "2025-02-17T12:28:56.211262Z",
     "shell.execute_reply": "2025-02-17T12:28:56.209843Z"
    },
    "papermill": {
     "duration": 0.030769,
     "end_time": "2025-02-17T12:28:56.213080",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.182311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_movies['genres'] = filtered_movies['genres'].str.split('|')\n",
    "filtered_movies['genres'] = filtered_movies['genres'].fillna('').astype('str')\n",
    "filtered_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9087c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.235793Z",
     "iopub.status.busy": "2025-02-17T12:28:56.235361Z",
     "iopub.status.idle": "2025-02-17T12:28:56.276746Z",
     "shell.execute_reply": "2025-02-17T12:28:56.275536Z"
    },
    "papermill": {
     "duration": 0.05504,
     "end_time": "2025-02-17T12:28:56.278981",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.223941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tf_idf_matrix(movies_dataset):\n",
    "    tf_idf = TfidfVectorizer(analyzer = 'word', ngram_range=(1,1), min_df=0)\n",
    "    tfidf_matrix = tf_idf.fit_transform(movies_dataset['genres'])\n",
    "    return tfidf_matrix\n",
    "tf_matrix = tf_idf_matrix(filtered_movies)\n",
    "tf_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11238634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.302289Z",
     "iopub.status.busy": "2025-02-17T12:28:56.301948Z",
     "iopub.status.idle": "2025-02-17T12:28:56.564376Z",
     "shell.execute_reply": "2025-02-17T12:28:56.563443Z"
    },
    "papermill": {
     "duration": 0.276611,
     "end_time": "2025-02-17T12:28:56.566380",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.289769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(matrix):\n",
    "    _cosine = linear_kernel(matrix, matrix)\n",
    "    return _cosine\n",
    "cosine_matrix = cosine_similarity(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172c6dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.589346Z",
     "iopub.status.busy": "2025-02-17T12:28:56.589005Z",
     "iopub.status.idle": "2025-02-17T12:28:56.595825Z",
     "shell.execute_reply": "2025-02-17T12:28:56.594564Z"
    },
    "papermill": {
     "duration": 0.020607,
     "end_time": "2025-02-17T12:28:56.597938",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.577331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f7fe1",
   "metadata": {
    "papermill": {
     "duration": 0.01049,
     "end_time": "2025-02-17T12:28:56.619684",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.609194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Sequential Matrix Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6db60d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.643388Z",
     "iopub.status.busy": "2025-02-17T12:28:56.643024Z",
     "iopub.status.idle": "2025-02-17T12:28:56.675011Z",
     "shell.execute_reply": "2025-02-17T12:28:56.673735Z"
    },
    "papermill": {
     "duration": 0.045874,
     "end_time": "2025-02-17T12:28:56.676889",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.631015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings['movieId'] = ratings['movieId'].copy().map(movie_id_to_index)\n",
    "max_movie_id = ratings['movieId'].max()\n",
    "\n",
    "print(\"Maximum movieId in ratings dataframe:\", max_movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66e625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:56.701603Z",
     "iopub.status.busy": "2025-02-17T12:28:56.701197Z",
     "iopub.status.idle": "2025-02-17T12:28:56.980820Z",
     "shell.execute_reply": "2025-02-17T12:28:56.979656Z"
    },
    "papermill": {
     "duration": 0.293658,
     "end_time": "2025-02-17T12:28:56.982643",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.688985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_ratings = ratings.sort_values(by=['userId', 'timestamp'])\n",
    "sorted_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a2a22d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:57.006854Z",
     "iopub.status.busy": "2025-02-17T12:28:57.006501Z",
     "iopub.status.idle": "2025-02-17T12:28:59.493466Z",
     "shell.execute_reply": "2025-02-17T12:28:59.492329Z"
    },
    "papermill": {
     "duration": 2.501096,
     "end_time": "2025-02-17T12:28:59.495377",
     "exception": false,
     "start_time": "2025-02-17T12:28:56.994281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "transitions = defaultdict(int)\n",
    "for user, group in sorted_ratings.groupby('userId'):\n",
    "    movies = group['movieId'].tolist()\n",
    "    for i in range(len(movies) - 1):\n",
    "        transitions[(movies[i], movies[i + 1])] += 1\n",
    "\n",
    "transition_matrix = defaultdict(dict)\n",
    "movie_counts = defaultdict(int)\n",
    "\n",
    "for (movie_i, movie_j), count in transitions.items():\n",
    "    movie_counts[movie_i] += count\n",
    "\n",
    "for (movie_i, movie_j), count in transitions.items():\n",
    "    transition_matrix[movie_i][movie_j] = count / movie_counts[movie_i]\n",
    "\n",
    "unique_movies = sorted(set(sorted_ratings['movieId']))\n",
    "movie_to_idx = {movie: idx for idx, movie in enumerate(unique_movies)}\n",
    "n_movies = len(unique_movies)\n",
    "\n",
    "sequential_matrix = np.zeros((n_movies, n_movies))\n",
    "for movie_i, neighbors in transition_matrix.items():\n",
    "    for movie_j, prob in neighbors.items():\n",
    "        sequential_matrix[movie_to_idx[movie_i], movie_to_idx[movie_j]] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cecade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:59.520036Z",
     "iopub.status.busy": "2025-02-17T12:28:59.519647Z",
     "iopub.status.idle": "2025-02-17T12:28:59.525966Z",
     "shell.execute_reply": "2025-02-17T12:28:59.524844Z"
    },
    "papermill": {
     "duration": 0.020876,
     "end_time": "2025-02-17T12:28:59.527748",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.506872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequential_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95edb7fa",
   "metadata": {
    "papermill": {
     "duration": 0.011931,
     "end_time": "2025-02-17T12:28:59.606889",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.594958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Getting a sequence array for SASRec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bda360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:59.632576Z",
     "iopub.status.busy": "2025-02-17T12:28:59.632181Z",
     "iopub.status.idle": "2025-02-17T12:28:59.674664Z",
     "shell.execute_reply": "2025-02-17T12:28:59.673404Z"
    },
    "papermill": {
     "duration": 0.05715,
     "end_time": "2025-02-17T12:28:59.676511",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.619361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_ratings = sorted_ratings[['userId', 'movieId']].copy()\n",
    "filtered_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355c6a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:59.702195Z",
     "iopub.status.busy": "2025-02-17T12:28:59.701854Z",
     "iopub.status.idle": "2025-02-17T12:28:59.710470Z",
     "shell.execute_reply": "2025-02-17T12:28:59.709372Z"
    },
    "papermill": {
     "duration": 0.023725,
     "end_time": "2025-02-17T12:28:59.712169",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.688444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_array = filtered_ratings.to_numpy(dtype=np.int32)\n",
    "ratings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3270a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:59.737968Z",
     "iopub.status.busy": "2025-02-17T12:28:59.737570Z",
     "iopub.status.idle": "2025-02-17T12:28:59.743359Z",
     "shell.execute_reply": "2025-02-17T12:28:59.742522Z"
    },
    "papermill": {
     "duration": 0.020898,
     "end_time": "2025-02-17T12:28:59.745081",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.724183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b39eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:59.770342Z",
     "iopub.status.busy": "2025-02-17T12:28:59.770016Z",
     "iopub.status.idle": "2025-02-17T12:28:59.789603Z",
     "shell.execute_reply": "2025-02-17T12:28:59.788297Z"
    },
    "papermill": {
     "duration": 0.034528,
     "end_time": "2025-02-17T12:28:59.791625",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.757097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_users = filtered_ratings['userId'].nunique()\n",
    "num_items = filtered_ratings['movieId'].nunique()\n",
    "\n",
    "print(f\"Number of Users: {num_users}\")\n",
    "print(f\"Number of Items (Movies): {num_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df315b",
   "metadata": {
    "papermill": {
     "duration": 0.011682,
     "end_time": "2025-02-17T12:28:59.815951",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.804269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Hybrid Matrix Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2949d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:59.842281Z",
     "iopub.status.busy": "2025-02-17T12:28:59.841902Z",
     "iopub.status.idle": "2025-02-17T12:28:59.846527Z",
     "shell.execute_reply": "2025-02-17T12:28:59.845338Z"
    },
    "papermill": {
     "duration": 0.020165,
     "end_time": "2025-02-17T12:28:59.848570",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.828405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c5e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:59.875102Z",
     "iopub.status.busy": "2025-02-17T12:28:59.874694Z",
     "iopub.status.idle": "2025-02-17T12:28:59.954459Z",
     "shell.execute_reply": "2025-02-17T12:28:59.953002Z"
    },
    "papermill": {
     "duration": 0.095796,
     "end_time": "2025-02-17T12:28:59.956689",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.860893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hybrid_matrix = alpha * sequential_matrix + beta * cosine_matrix\n",
    "hybrid_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57e6b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:28:59.983247Z",
     "iopub.status.busy": "2025-02-17T12:28:59.982873Z",
     "iopub.status.idle": "2025-02-17T12:29:00.021326Z",
     "shell.execute_reply": "2025-02-17T12:29:00.019880Z"
    },
    "papermill": {
     "duration": 0.05371,
     "end_time": "2025-02-17T12:29:00.023316",
     "exception": false,
     "start_time": "2025-02-17T12:28:59.969606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparsity = (np.sum(hybrid_matrix == 0) / hybrid_matrix.size) * 100\n",
    "print(f\"Sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a3dad",
   "metadata": {
    "papermill": {
     "duration": 0.012678,
     "end_time": "2025-02-17T12:29:00.049056",
     "exception": false,
     "start_time": "2025-02-17T12:29:00.036378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e511f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:29:00.140704Z",
     "iopub.status.busy": "2025-02-17T12:29:00.140287Z",
     "iopub.status.idle": "2025-02-17T12:30:32.793143Z",
     "shell.execute_reply": "2025-02-17T12:30:32.791926Z"
    },
    "papermill": {
     "duration": 92.668527,
     "end_time": "2025-02-17T12:30:32.795317",
     "exception": false,
     "start_time": "2025-02-17T12:29:00.126790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_node_timestamps(sorted_ratings, num_nodes):\n",
    "    node_timestamps = torch.zeros(num_nodes) \n",
    "    counts = torch.zeros(num_nodes)\n",
    "\n",
    "    for index, row in sorted_ratings.iterrows():\n",
    "        node_id = row['movieId'] - 1\n",
    "        timestamp = row['timestamp']\n",
    "        \n",
    "        node_timestamps[node_id] += timestamp\n",
    "        counts[node_id] += 1  \n",
    "    \n",
    "    counts[counts == 0] = 1\n",
    "    node_timestamps /= counts\n",
    "    \n",
    "    node_timestamps = (node_timestamps - node_timestamps.min()) / (node_timestamps.max() - node_timestamps.min())\n",
    "\n",
    "    return node_timestamps\n",
    "\n",
    "num_nodes = hybrid_matrix.shape[0]\n",
    "timestamps = compute_node_timestamps(sorted_ratings, num_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5a749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:32.888556Z",
     "iopub.status.busy": "2025-02-17T12:30:32.888161Z",
     "iopub.status.idle": "2025-02-17T12:30:32.897327Z",
     "shell.execute_reply": "2025-02-17T12:30:32.896448Z"
    },
    "papermill": {
     "duration": 0.024484,
     "end_time": "2025-02-17T12:30:32.899001",
     "exception": false,
     "start_time": "2025-02-17T12:30:32.874517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def normalize_adjacency(adj):\n",
    "    degree = torch.sum(adj, dim=1, keepdim=True)\n",
    "    degree_inv_sqrt = torch.pow(degree, -0.5)\n",
    "    adj_normalized = degree_inv_sqrt * adj * degree_inv_sqrt.t()\n",
    "    return adj_normalized\n",
    "\n",
    "def time_decay_function(timestamps, decay_factor=0.1):\n",
    "    current_time = torch.max(timestamps)\n",
    "    time_diff = current_time - timestamps\n",
    "    return torch.exp(-decay_factor * time_diff)\n",
    "\n",
    "def perturb_timestamps(timestamps, lambda_factor=0.5):\n",
    "    noise = torch.randn_like(timestamps) * lambda_factor * torch.std(timestamps)\n",
    "    perturbed_timestamps = timestamps + noise\n",
    "    return torch.clamp(perturbed_timestamps, min=0) \n",
    "\n",
    "def personalized_ppr(adj, alpha=0.1, max_iter=10, tol=1e-6):\n",
    "    num_nodes = adj.shape[0]\n",
    "    adj_norm = normalize_adjacency(adj)\n",
    "    ppr_matrix = torch.eye(num_nodes, device=adj.device)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        new_ppr = alpha * torch.eye(num_nodes, device=adj.device) + (1 - alpha) * torch.mm(adj_norm, ppr_matrix)\n",
    "        if torch.norm(new_ppr - ppr_matrix) < tol:\n",
    "            break \n",
    "        ppr_matrix = new_ppr\n",
    "\n",
    "    return ppr_matrix\n",
    "\n",
    "def enhanced_hybrid_matrix(adj_matrix, timestamps, alpha=0.1):\n",
    "    time_decay_weights = time_decay_function(timestamps)\n",
    "    adj_matrix = adj_matrix * time_decay_weights.unsqueeze(1)\n",
    "    adj_matrix = personalized_ppr(adj_matrix, alpha=alpha)\n",
    "    return adj_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b298c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:32.926081Z",
     "iopub.status.busy": "2025-02-17T12:30:32.925702Z",
     "iopub.status.idle": "2025-02-17T12:30:43.068708Z",
     "shell.execute_reply": "2025-02-17T12:30:43.067452Z"
    },
    "papermill": {
     "duration": 10.159114,
     "end_time": "2025-02-17T12:30:43.070788",
     "exception": false,
     "start_time": "2025-02-17T12:30:32.911674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adj_matrix = torch.tensor(hybrid_matrix, dtype=torch.float32)\n",
    "timestamps = perturb_timestamps(timestamps)\n",
    "\n",
    "alpha_ppr = 0.1\n",
    "adj_matrix = enhanced_hybrid_matrix(adj_matrix, timestamps, alpha_ppr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98187256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:43.138456Z",
     "iopub.status.busy": "2025-02-17T12:30:43.138095Z",
     "iopub.status.idle": "2025-02-17T12:30:43.206685Z",
     "shell.execute_reply": "2025-02-17T12:30:43.205580Z"
    },
    "papermill": {
     "duration": 0.084202,
     "end_time": "2025-02-17T12:30:43.208491",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.124289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_movies = adj_matrix.shape[0]\n",
    "padding_row = torch.zeros((1, num_movies))\n",
    "adj_matrix = torch.cat([adj_matrix, padding_row], dim=0)\n",
    "padding_col = torch.zeros((num_movies + 1, 1))\n",
    "adj_matrix = torch.cat([adj_matrix, padding_col], dim=1)\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b474dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:43.347073Z",
     "iopub.status.busy": "2025-02-17T12:30:43.346702Z",
     "iopub.status.idle": "2025-02-17T12:30:43.353344Z",
     "shell.execute_reply": "2025-02-17T12:30:43.352404Z"
    },
    "papermill": {
     "duration": 0.022867,
     "end_time": "2025-02-17T12:30:43.355255",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.332388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "class TemporalGCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(TemporalGCNLayer, self).__init__()\n",
    "        self.W = nn.Linear(in_features, out_features)\n",
    "        self.time_embedding = nn.Linear(1, out_features)\n",
    "        self.update_mlp = nn.Sequential(\n",
    "            nn.Linear(out_features, out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_features, out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, node_features, adjacency_matrix, timestamps):\n",
    "        temporal_features = self.time_embedding(timestamps.unsqueeze(-1))\n",
    "        node_features = self.W(node_features) + temporal_features\n",
    "        node_features = torch.matmul(adjacency_matrix, node_features)\n",
    "        return self.update_mlp(node_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9d0f3",
   "metadata": {
    "papermill": {
     "duration": 0.013953,
     "end_time": "2025-02-17T12:30:43.382639",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.368686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SASRec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0479d0",
   "metadata": {
    "papermill": {
     "duration": 0.012859,
     "end_time": "2025-02-17T12:30:43.472399",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.459540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da85c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:43.500067Z",
     "iopub.status.busy": "2025-02-17T12:30:43.499722Z",
     "iopub.status.idle": "2025-02-17T12:30:43.504484Z",
     "shell.execute_reply": "2025-02-17T12:30:43.503384Z"
    },
    "papermill": {
     "duration": 0.020677,
     "end_time": "2025-02-17T12:30:43.506342",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.485665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Process, Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40013548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:43.534166Z",
     "iopub.status.busy": "2025-02-17T12:30:43.533779Z",
     "iopub.status.idle": "2025-02-17T12:30:43.550322Z",
     "shell.execute_reply": "2025-02-17T12:30:43.549263Z"
    },
    "papermill": {
     "duration": 0.032757,
     "end_time": "2025-02-17T12:30:43.552338",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.519581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_index(ui_mat):\n",
    "    n_users = ui_mat[:,0].max()\n",
    "    n_items = ui_mat[:,1].max()\n",
    "\n",
    "    u2i_index = [[] for _ in range(n_users + 1)]\n",
    "    i2u_index = [[] for _ in range(n_items + 1)]\n",
    "\n",
    "    for ui_pair in ui_mat:\n",
    "        u2i_index[ui_pair[0]].append(ui_pair[1])\n",
    "        i2u_index[ui_pair[1]].append(ui_pair[0])\n",
    "\n",
    "    return u2i_index, i2u_index\n",
    "\n",
    "def random_neq(l, r, s):\n",
    "    t = np.random.randint(l, r)\n",
    "    while t in s:\n",
    "        t = np.random.randint(l, r)\n",
    "    return t\n",
    "\n",
    "def sample_function(user_train, usernum, itemnum, batch_size, maxlen, result_queue, SEED):\n",
    "    def sample(uid):\n",
    "        while len(user_train[uid]) <= 1: uid = np.random.randint(1, usernum + 1)\n",
    "\n",
    "        seq = np.zeros([maxlen], dtype=np.int32)\n",
    "        pos = np.zeros([maxlen], dtype=np.int32)\n",
    "        neg = np.zeros([maxlen], dtype=np.int32)\n",
    "        nxt = user_train[uid][-1]\n",
    "        idx = maxlen - 1\n",
    "\n",
    "        ts = set(user_train[uid])\n",
    "        for i in reversed(user_train[uid][:-1]):\n",
    "            seq[idx] = i\n",
    "            pos[idx] = nxt\n",
    "            if nxt != 0: neg[idx] = random_neq(1, itemnum + 1, ts)\n",
    "            nxt = i\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "\n",
    "        return (uid, seq, pos, neg)\n",
    "\n",
    "    np.random.seed(SEED)\n",
    "    uids = np.arange(1, usernum+1, dtype=np.int32)\n",
    "    counter = 0\n",
    "    while True:\n",
    "        if counter % usernum == 0:\n",
    "            np.random.shuffle(uids)\n",
    "        one_batch = []\n",
    "        for i in range(batch_size):\n",
    "            one_batch.append(sample(uids[counter % usernum]))\n",
    "            counter += 1\n",
    "        result_queue.put(zip(*one_batch))\n",
    "\n",
    "\n",
    "class WarpSampler(object):\n",
    "    def __init__(self, User, usernum, itemnum, batch_size=64, maxlen=10, n_workers=1):\n",
    "        self.result_queue = Queue(maxsize=n_workers * 10)\n",
    "        self.processors = []\n",
    "        for i in range(n_workers):\n",
    "            self.processors.append(\n",
    "                Process(target=sample_function, args=(User,\n",
    "                                                      usernum,\n",
    "                                                      itemnum,\n",
    "                                                      batch_size,\n",
    "                                                      maxlen,\n",
    "                                                      self.result_queue,\n",
    "                                                      np.random.randint(2e9)\n",
    "                                                      )))\n",
    "            self.processors[-1].daemon = True\n",
    "            self.processors[-1].start()\n",
    "\n",
    "    def next_batch(self):\n",
    "        return self.result_queue.get()\n",
    "\n",
    "    def close(self):\n",
    "        for p in self.processors:\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "\n",
    "\n",
    "def data_partition(df):\n",
    "    usernum = 0\n",
    "    itemnum = 0\n",
    "    User = defaultdict(list)\n",
    "    user_train = {}\n",
    "    user_valid = {}\n",
    "    user_test = {}\n",
    "    for index, row in df.iterrows():\n",
    "        u = row[0] \n",
    "        i = row[1]\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        usernum = max(u, usernum)\n",
    "        itemnum = max(i, itemnum)\n",
    "        User[u].append(i)\n",
    "\n",
    "    for user in User:\n",
    "        nfeedback = len(User[user])\n",
    "        if nfeedback < 3:\n",
    "            user_train[user] = User[user]\n",
    "            user_valid[user] = []\n",
    "            user_test[user] = []\n",
    "        else:\n",
    "            user_train[user] = User[user][:-2]\n",
    "            user_valid[user] = []\n",
    "            user_valid[user].append(User[user][-2])\n",
    "            user_test[user] = []\n",
    "            user_test[user].append(User[user][-1])\n",
    "    return [user_train, user_valid, user_test, usernum, itemnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fb1f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:43.580703Z",
     "iopub.status.busy": "2025-02-17T12:30:43.580290Z",
     "iopub.status.idle": "2025-02-17T12:30:43.595819Z",
     "shell.execute_reply": "2025-02-17T12:30:43.594503Z"
    },
    "papermill": {
     "duration": 0.031983,
     "end_time": "2025-02-17T12:30:43.597789",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.565806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "\n",
    "    NDCG = 0.0\n",
    "    HT = 0.0\n",
    "    MRR = 0.0\n",
    "    valid_user = 0.0\n",
    "\n",
    "    if usernum > 10000:\n",
    "        users = random.sample(range(1, usernum + 1), 10000)\n",
    "    else:\n",
    "        users = range(1, usernum + 1)\n",
    "    \n",
    "    for u in users:\n",
    "        if len(train[u]) < 1 or len(test[u]) < 1: continue\n",
    "\n",
    "        seq = np.zeros([args['maxlen']], dtype=np.int32)\n",
    "        idx = args['maxlen'] - 1\n",
    "        seq[idx] = valid[u][0]\n",
    "        idx -= 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        item_idx = [test[u][0]]\n",
    "        for _ in range(100):\n",
    "            t = np.random.randint(1, itemnum + 1)\n",
    "            while t in rated: t = np.random.randint(1, itemnum + 1)\n",
    "            item_idx.append(t)\n",
    "\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n",
    "        predictions = predictions[0]  \n",
    "\n",
    "        rank = predictions.argsort().argsort()[0].item()\n",
    "\n",
    "        valid_user += 1\n",
    "\n",
    "        if rank < 10:\n",
    "            NDCG += 1 / np.log2(rank + 2)\n",
    "            HT += 1\n",
    "            MRR += 1 / (rank + 1)  \n",
    "\n",
    "    return NDCG / valid_user, HT / valid_user, MRR / valid_user\n",
    "\n",
    "\n",
    "def evaluate_valid(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "\n",
    "    NDCG = 0.0\n",
    "    HT = 0.0\n",
    "    MRR = 0.0 \n",
    "    valid_user = 0.0\n",
    "    if usernum > 10000:\n",
    "        users = random.sample(range(1, usernum + 1), 10000)\n",
    "    else:\n",
    "        users = range(1, usernum + 1)\n",
    "    \n",
    "    for u in users:\n",
    "        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n",
    "\n",
    "        seq = np.zeros([args['maxlen']], dtype=np.int32)\n",
    "        idx = args['maxlen'] - 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        item_idx = [valid[u][0]]\n",
    "        for _ in range(100):\n",
    "            t = np.random.randint(1, itemnum + 1)\n",
    "            while t in rated: t = np.random.randint(1, itemnum + 1)\n",
    "            item_idx.append(t)\n",
    "\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n",
    "        predictions = predictions[0]\n",
    "\n",
    "        rank = predictions.argsort().argsort()[0].item()\n",
    "\n",
    "        valid_user += 1\n",
    "\n",
    "        if rank < 10:\n",
    "            NDCG += 1 / np.log2(rank + 2)\n",
    "            HT += 1\n",
    "            MRR += 1 / (rank + 1)\n",
    "\n",
    "    return NDCG / valid_user, HT / valid_user, MRR / valid_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08695df3",
   "metadata": {
    "papermill": {
     "duration": 0.012963,
     "end_time": "2025-02-17T12:30:43.624545",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.611582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a81bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:43.652454Z",
     "iopub.status.busy": "2025-02-17T12:30:43.652058Z",
     "iopub.status.idle": "2025-02-17T12:30:43.675111Z",
     "shell.execute_reply": "2025-02-17T12:30:43.673841Z"
    },
    "papermill": {
     "duration": 0.03933,
     "end_time": "2025-02-17T12:30:43.677087",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.637757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class PointWiseFeedForward(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout_rate):\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n",
    "        outputs = outputs.transpose(-1, -2) \n",
    "        outputs += inputs\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(self, user_num, item_num, args, adj_matrix, timestamps):\n",
    "        super(SASRec, self).__init__()\n",
    "\n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "        self.dev = args['device']\n",
    "        self.timestamps = timestamps \n",
    "        self.gcn_layers = nn.ModuleList([\n",
    "            TemporalGCNLayer(args['hidden_units'], args['hidden_units']) \n",
    "            for _ in range(args['num_gcn_layers'])\n",
    "        ])\n",
    "\n",
    "        self.adj_matrix = adj_matrix\n",
    "        self.item_emb = nn.Embedding(item_num + 1, args['hidden_units'], padding_idx=0)\n",
    "        \n",
    "        self.pos_emb = nn.Embedding(args['maxlen'] + 1, args['hidden_units'], padding_idx=0)\n",
    "        self.emb_dropout = nn.Dropout(p=args['dropout_rate'])\n",
    "\n",
    "        self.attention_layernorms = nn.ModuleList()\n",
    "        self.attention_layers = nn.ModuleList()\n",
    "        self.forward_layernorms = nn.ModuleList()\n",
    "        self.forward_layers = nn.ModuleList()\n",
    "        self.last_layernorm = nn.LayerNorm(args['hidden_units'], eps=1e-8)\n",
    "\n",
    "        for _ in range(args['num_blocks']):\n",
    "            new_attn_layernorm = nn.LayerNorm(args['hidden_units'], eps=1e-8)\n",
    "            self.attention_layernorms.append(new_attn_layernorm)\n",
    "\n",
    "            new_attn_layer = nn.MultiheadAttention(args['hidden_units'],\n",
    "                                                   args['num_heads'],\n",
    "                                                   args['dropout_rate'])\n",
    "            self.attention_layers.append(new_attn_layer)\n",
    "\n",
    "            new_fwd_layernorm = nn.LayerNorm(args['hidden_units'], eps=1e-8)\n",
    "            self.forward_layernorms.append(new_fwd_layernorm)\n",
    "\n",
    "            new_fwd_layer = PointWiseFeedForward(args['hidden_units'], args['dropout_rate'])\n",
    "            self.forward_layers.append(new_fwd_layer)\n",
    "            \n",
    "    def get_graph_embeddings(self):\n",
    "        layer_output = F.embedding(torch.arange(self.item_num + 1, device=self.dev), self.item_emb.weight)\n",
    "        for gcn_layer in self.gcn_layers:\n",
    "            layer_output = gcn_layer(layer_output, self.adj_matrix, self.timestamps)\n",
    "\n",
    "        return layer_output\n",
    "\n",
    "    def augment_sequence(self, log_seqs, dropout_prob=0.2):\n",
    "        mask = torch.rand(log_seqs.shape, device=self.dev) > dropout_prob\n",
    "        return log_seqs * mask\n",
    "        \n",
    "    def log2feats(self, log_seqs, augment=False):\n",
    "        gcn_embeddings = self.get_graph_embeddings()\n",
    "        raw_item_embeddings = self.item_emb.weight  \n",
    "\n",
    "        enhanced_item_embeddings = raw_item_embeddings + gcn_embeddings\n",
    "        seqs = F.embedding(torch.LongTensor(log_seqs).to(self.dev), enhanced_item_embeddings)\n",
    "\n",
    "        if augment:\n",
    "            seqs_aug = self.augment_sequence(seqs)\n",
    "        else:\n",
    "            seqs_aug = seqs  \n",
    "            \n",
    "        seqs *= self.item_emb.embedding_dim ** 0.5\n",
    "        poss = np.tile(np.arange(1, log_seqs.shape[1] + 1), [log_seqs.shape[0], 1])\n",
    "        poss *= (log_seqs != 0)\n",
    "        seqs += self.pos_emb(torch.LongTensor(poss).to(self.dev))\n",
    "        seqs = self.emb_dropout(seqs)\n",
    "\n",
    "        tl = seqs.shape[1]  \n",
    "        attention_mask = ~torch.tril(torch.ones((tl, tl), dtype=torch.bool, device=self.dev))\n",
    "\n",
    "        for i in range(len(self.attention_layers)):\n",
    "            seqs = torch.transpose(seqs, 0, 1)\n",
    "            Q = self.attention_layernorms[i](seqs)\n",
    "            mha_outputs, _ = self.attention_layers[i](Q, seqs, seqs, attn_mask=attention_mask)\n",
    "            seqs = Q + mha_outputs\n",
    "            seqs = torch.transpose(seqs, 0, 1)\n",
    "\n",
    "            seqs = self.forward_layernorms[i](seqs)\n",
    "            seqs = self.forward_layers[i](seqs)\n",
    "\n",
    "        log_feats = self.last_layernorm(seqs)\n",
    "        log_feats_aug = self.last_layernorm(seqs_aug)\n",
    "        \n",
    "        return log_feats, log_feats_aug\n",
    "\n",
    "    def contrastive_loss(self, z_i, z_j, temperature=0.5):\n",
    "        z_i = F.normalize(z_i, dim=-1)\n",
    "        z_j = F.normalize(z_j, dim=-1)\n",
    "\n",
    "        z_i = z_i.view(128, -1)\n",
    "        z_j = z_j.view(128, -1) \n",
    "        \n",
    "        pos_sim = torch.exp(torch.sum(z_i * z_j, dim=-1) / temperature)\n",
    "        neg_sim = torch.exp(torch.matmul(z_i, z_j.T) / temperature)\n",
    "    \n",
    "        loss = -torch.log(pos_sim / torch.sum(neg_sim, dim=-1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def forward(self, user_ids, log_seqs, pos_seqs, neg_seqs, contrastive=True):\n",
    "        log_feats, log_feats_aug = self.log2feats(log_seqs)\n",
    "        \n",
    "        gcn_embeddings = self.get_graph_embeddings()\n",
    "        enhanced_item_embeddings = self.item_emb.weight + gcn_embeddings \n",
    "        pos_embs = self.item_emb(torch.LongTensor(pos_seqs).to(self.dev))\n",
    "        neg_embs = self.item_emb(torch.LongTensor(neg_seqs).to(self.dev))\n",
    "\n",
    "        pos_logits = (log_feats * pos_embs).sum(dim=-1)\n",
    "        neg_logits = (log_feats * neg_embs).sum(dim=-1)\n",
    "\n",
    "        if contrastive:\n",
    "            cl_loss = self.contrastive_loss(log_feats, log_feats_aug)\n",
    "        else:\n",
    "            cl_loss = 0\n",
    "\n",
    "        return pos_logits, neg_logits, cl_loss \n",
    "\n",
    "    def predict(self, user_ids, log_seqs, item_indices): \n",
    "        \"\"\"Generate predictions for given item indices.\"\"\"\n",
    "        log_feats, _ = self.log2feats(log_seqs)\n",
    "        final_feat = log_feats[:, -1, :]\n",
    "        gcn_embeddings = self.get_graph_embeddings()\n",
    "        enhanced_item_embeddings = self.item_emb.weight + gcn_embeddings  \n",
    "\n",
    "        item_embs = F.embedding(torch.LongTensor(item_indices).to(self.dev), enhanced_item_embeddings)\n",
    "        logits = item_embs.matmul(final_feat.unsqueeze(-1)).squeeze(-1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a00dbd",
   "metadata": {
    "papermill": {
     "duration": 0.013803,
     "end_time": "2025-02-17T12:30:43.704162",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.690359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8b51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:30:43.733737Z",
     "iopub.status.busy": "2025-02-17T12:30:43.733271Z",
     "iopub.status.idle": "2025-02-17T12:31:47.901393Z",
     "shell.execute_reply": "2025-02-17T12:31:47.900088Z"
    },
    "papermill": {
     "duration": 64.185817,
     "end_time": "2025-02-17T12:31:47.903393",
     "exception": false,
     "start_time": "2025-02-17T12:30:43.717576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "u2i_index, i2u_index = build_index(ratings_array)\n",
    "dataset = data_partition(filtered_ratings)\n",
    "[user_train, user_valid, user_test, usernum, itemnum] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff571241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:31:47.932258Z",
     "iopub.status.busy": "2025-02-17T12:31:47.931889Z",
     "iopub.status.idle": "2025-02-17T12:31:47.938001Z",
     "shell.execute_reply": "2025-02-17T12:31:47.936617Z"
    },
    "papermill": {
     "duration": 0.02309,
     "end_time": "2025-02-17T12:31:47.940168",
     "exception": false,
     "start_time": "2025-02-17T12:31:47.917078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(usernum, itemnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34052a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:31:47.971514Z",
     "iopub.status.busy": "2025-02-17T12:31:47.971123Z",
     "iopub.status.idle": "2025-02-17T12:31:47.980786Z",
     "shell.execute_reply": "2025-02-17T12:31:47.979614Z"
    },
    "papermill": {
     "duration": 0.027592,
     "end_time": "2025-02-17T12:31:47.982782",
     "exception": false,
     "start_time": "2025-02-17T12:31:47.955190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'batch_size': 128,\n",
    "    'lr': 0.001,\n",
    "    'maxlen': 50,\n",
    "    'hidden_units': 50,\n",
    "    'num_blocks': 2,\n",
    "    'num_epochs': 1000,\n",
    "    'num_heads': 1,\n",
    "    'dropout_rate': 0.2,\n",
    "    'l2_emb': 0.0,\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'inference_only': False,\n",
    "    'num_gcn_layers': 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b0724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:31:48.011643Z",
     "iopub.status.busy": "2025-02-17T12:31:48.011233Z",
     "iopub.status.idle": "2025-02-17T12:31:48.020208Z",
     "shell.execute_reply": "2025-02-17T12:31:48.018895Z"
    },
    "papermill": {
     "duration": 0.025556,
     "end_time": "2025-02-17T12:31:48.022069",
     "exception": false,
     "start_time": "2025-02-17T12:31:47.996513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_batch = (len(user_train) - 1) // args['batch_size'] + 1\n",
    "cc = 0.0\n",
    "for u in user_train:\n",
    "    cc += len(user_train[u])\n",
    "print('Average sequence length: %.2f' % (cc / len(user_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a2b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:31:48.051316Z",
     "iopub.status.busy": "2025-02-17T12:31:48.050983Z",
     "iopub.status.idle": "2025-02-17T12:31:48.175331Z",
     "shell.execute_reply": "2025-02-17T12:31:48.170956Z"
    },
    "papermill": {
     "duration": 0.143236,
     "end_time": "2025-02-17T12:31:48.178848",
     "exception": false,
     "start_time": "2025-02-17T12:31:48.035612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler = WarpSampler(user_train, usernum, itemnum, batch_size=args['batch_size'], maxlen=args['maxlen'], n_workers=3)\n",
    "model = SASRec(usernum, itemnum, args, adj_matrix, timestamps).to(args['device'])\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "        try:\n",
    "            torch.nn.init.xavier_normal_(param.data)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "model.pos_emb.weight.data[0, :] = 0\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9431bfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T12:31:48.238503Z",
     "iopub.status.busy": "2025-02-17T12:31:48.236372Z",
     "iopub.status.idle": "2025-02-17T18:56:37.517954Z",
     "shell.execute_reply": "2025-02-17T18:56:37.516841Z"
    },
    "papermill": {
     "duration": 23089.314067,
     "end_time": "2025-02-17T18:56:37.521185",
     "exception": false,
     "start_time": "2025-02-17T12:31:48.207118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "adam_optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], betas=(0.9, 0.98), weight_decay=1e-4)\n",
    "\n",
    "best_val_ndcg, best_val_hr, best_val_mrr = 0.0, 0.0, 0.0\n",
    "best_test_ndcg, best_test_hr, best_test_mrr = 0.0, 0.0, 0.0\n",
    "T = 0.0\n",
    "t0 = time.time()\n",
    "\n",
    "patience = 5\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "losses = []\n",
    "ndcgs = []\n",
    "hrs = []\n",
    "mrrs = []\n",
    "\n",
    "for epoch in range(1, args['num_epochs'] + 1):\n",
    "    for step in range(num_batch):  \n",
    "        u, seq, pos, neg = sampler.next_batch() \n",
    "        u, seq, pos, neg = np.array(u), np.array(seq), np.array(pos), np.array(neg)\n",
    "        pos_logits, neg_logits, cl_loss = model(u, seq, pos, neg, contrastive=True)\n",
    "        pos_labels, neg_labels = torch.ones(pos_logits.shape, device=args['device']), torch.zeros(neg_logits.shape, device=args['device'])\n",
    "        adam_optimizer.zero_grad()\n",
    "        indices = np.where(pos != 0)\n",
    "        loss = bce_criterion(pos_logits[indices], pos_labels[indices])\n",
    "        loss += bce_criterion(neg_logits[indices], neg_labels[indices])\n",
    "        for param in model.item_emb.parameters(): loss += args['l2_emb'] * torch.norm(param)\n",
    "        loss.backward()\n",
    "        adam_optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    print(f\"Loss in epoch {epoch} iteration {step}: {loss.item()}\")\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        model.eval()\n",
    "        t1 = time.time() - t0\n",
    "        T += t1\n",
    "        print('Evaluating', end='')\n",
    "        \n",
    "        t_test = evaluate(model, dataset, args)\n",
    "        t_valid = evaluate_valid(model, dataset, args)\n",
    "        \n",
    "        print(f'epoch:{epoch}, time: {T:.6f}(s), valid (NDCG@10: {t_valid[0]:.4f}, HR@10: {t_valid[1]:.4f}, MRR: {t_valid[2]:.4f}), '\n",
    "              f'test (NDCG@10: {t_test[0]:.4f}, HR@10: {t_test[1]:.4f}, MRR: {t_test[2]:.4f})')\n",
    "\n",
    "        ndcgs.append(t_valid[0])\n",
    "        hrs.append(t_valid[1])\n",
    "        mrrs.append(t_valid[2])\n",
    "    \n",
    "        if (t_valid[0] > best_val_ndcg or t_valid[1] > best_val_hr or t_valid[2] > best_val_mrr or\n",
    "            t_test[0] > best_test_ndcg or t_test[1] > best_test_hr or t_test[2] > best_test_mrr):\n",
    "            \n",
    "            best_val_ndcg = max(t_valid[0], best_val_ndcg)\n",
    "            best_val_hr = max(t_valid[1], best_val_hr)\n",
    "            best_val_mrr = max(t_valid[2], best_val_mrr)\n",
    "            best_test_ndcg = max(t_test[0], best_test_ndcg)\n",
    "            best_test_hr = max(t_test[1], best_test_hr)\n",
    "            best_test_mrr = max(t_test[2], best_test_mrr)\n",
    "            \n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "    \n",
    "        if no_improvement_epochs >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}. No improvement in validation NDCG/HR/MRR for {patience} epochs.\")\n",
    "            break\n",
    "    \n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "ax[0, 0].plot(range(1, len(losses) + 1), losses, label='Loss', color='red')\n",
    "ax[0, 0].set_xlabel('Epoch')\n",
    "ax[0, 0].set_ylabel('Loss')\n",
    "ax[0, 0].set_title('Loss vs Epoch')\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "ax[0, 1].plot(range(20, len(ndcgs) * 20 + 1, 20), ndcgs, label='NDCG@10', color='blue')\n",
    "ax[0, 1].set_xlabel('Epoch')\n",
    "ax[0, 1].set_ylabel('NDCG@10')\n",
    "ax[0, 1].set_title('NDCG@10 vs Epoch')\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "ax[1, 0].plot(range(20, len(hrs) * 20 + 1, 20), hrs, label='HR@10', color='green')\n",
    "ax[1, 0].set_xlabel('Epoch')\n",
    "ax[1, 0].set_ylabel('HR@10')\n",
    "ax[1, 0].set_title('HR@10 vs Epoch')\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "ax[1, 1].plot(range(20, len(mrrs) * 20 + 1, 20), mrrs, label='MRR', color='purple')\n",
    "ax[1, 1].set_xlabel('Epoch')\n",
    "ax[1, 1].set_ylabel('MRR')\n",
    "ax[1, 1].set_title('MRR vs Epoch')\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Best Validation Metrics: '\n",
    "      f'NDCG@10: {best_val_ndcg:.4f}, HR@10: {best_val_hr:.4f}, MRR: {best_val_mrr:.4f}')\n",
    "print(f'Best Test Metrics: '\n",
    "      f'NDCG@10: {best_test_ndcg:.4f}, HR@10: {best_test_hr:.4f}, MRR: {best_test_mrr:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb285ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T18:56:37.646279Z",
     "iopub.status.busy": "2025-02-17T18:56:37.645781Z",
     "iopub.status.idle": "2025-02-17T18:56:37.795068Z",
     "shell.execute_reply": "2025-02-17T18:56:37.793876Z"
    },
    "papermill": {
     "duration": 0.213938,
     "end_time": "2025-02-17T18:56:37.797072",
     "exception": false,
     "start_time": "2025-02-17T18:56:37.583134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4004281,
     "sourceId": 6969416,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23271.927931,
   "end_time": "2025-02-17T18:56:41.546788",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-17T12:28:49.618857",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
