{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:11.147552Z",
     "iopub.status.busy": "2025-02-11T07:03:11.147219Z",
     "iopub.status.idle": "2025-02-11T07:03:12.135320Z",
     "shell.execute_reply": "2025-02-11T07:03:12.134521Z",
     "shell.execute_reply.started": "2025-02-11T07:03:11.147525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Matrix Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:12.238978Z",
     "iopub.status.busy": "2025-02-11T07:03:12.238403Z",
     "iopub.status.idle": "2025-02-11T07:03:12.285536Z",
     "shell.execute_reply": "2025-02-11T07:03:12.284698Z",
     "shell.execute_reply.started": "2025-02-11T07:03:12.238932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('/kaggle/input/movielens-1m/movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:12.935441Z",
     "iopub.status.busy": "2025-02-11T07:03:12.935107Z",
     "iopub.status.idle": "2025-02-11T07:03:13.415059Z",
     "shell.execute_reply": "2025-02-11T07:03:13.414105Z",
     "shell.execute_reply.started": "2025-02-11T07:03:12.935417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('/kaggle/input/movielens-1m/ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:13.520103Z",
     "iopub.status.busy": "2025-02-11T07:03:13.519729Z",
     "iopub.status.idle": "2025-02-11T07:03:13.552332Z",
     "shell.execute_reply": "2025-02-11T07:03:13.551512Z",
     "shell.execute_reply.started": "2025-02-11T07:03:13.520066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ratings_movie_ids = ratings['movieId'].unique()\n",
    "filtered_movies = movies[movies['movieId'].isin(ratings_movie_ids)]\n",
    "filtered_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:13.981819Z",
     "iopub.status.busy": "2025-02-11T07:03:13.981494Z",
     "iopub.status.idle": "2025-02-11T07:03:13.989252Z",
     "shell.execute_reply": "2025-02-11T07:03:13.988380Z",
     "shell.execute_reply.started": "2025-02-11T07:03:13.981795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filtered_movies['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:16.290970Z",
     "iopub.status.busy": "2025-02-11T07:03:16.290613Z",
     "iopub.status.idle": "2025-02-11T07:03:16.298197Z",
     "shell.execute_reply": "2025-02-11T07:03:16.296934Z",
     "shell.execute_reply.started": "2025-02-11T07:03:16.290940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movie_id_to_index = {movie_id: idx + 1 for idx, movie_id in enumerate(filtered_movies['movieId'])}\n",
    "len(movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:16.836434Z",
     "iopub.status.busy": "2025-02-11T07:03:16.836112Z",
     "iopub.status.idle": "2025-02-11T07:03:16.850208Z",
     "shell.execute_reply": "2025-02-11T07:03:16.849186Z",
     "shell.execute_reply.started": "2025-02-11T07:03:16.836411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filtered_movies['movieId'] = filtered_movies['movieId'].copy().map(movie_id_to_index)\n",
    "filtered_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:17.491633Z",
     "iopub.status.busy": "2025-02-11T07:03:17.491323Z",
     "iopub.status.idle": "2025-02-11T07:03:17.496983Z",
     "shell.execute_reply": "2025-02-11T07:03:17.496145Z",
     "shell.execute_reply.started": "2025-02-11T07:03:17.491610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_movie_id = filtered_movies['movieId'].max()\n",
    "\n",
    "print(\"Maximum movieId in movies dataframe:\", max_movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:18.232836Z",
     "iopub.status.busy": "2025-02-11T07:03:18.232520Z",
     "iopub.status.idle": "2025-02-11T07:03:18.249744Z",
     "shell.execute_reply": "2025-02-11T07:03:18.248839Z",
     "shell.execute_reply.started": "2025-02-11T07:03:18.232812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filtered_movies['genres'] = filtered_movies['genres'].str.split('|')\n",
    "filtered_movies['genres'] = filtered_movies['genres'].fillna('').astype('str')\n",
    "filtered_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:20.126492Z",
     "iopub.status.busy": "2025-02-11T07:03:20.126142Z",
     "iopub.status.idle": "2025-02-11T07:03:20.163277Z",
     "shell.execute_reply": "2025-02-11T07:03:20.162334Z",
     "shell.execute_reply.started": "2025-02-11T07:03:20.126465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tf_idf_matrix(movies_dataset):\n",
    "    tf_idf = TfidfVectorizer(analyzer = 'word', ngram_range=(1,1), min_df=0)\n",
    "    tfidf_matrix = tf_idf.fit_transform(movies_dataset['genres'])\n",
    "    return tfidf_matrix\n",
    "tf_matrix = tf_idf_matrix(filtered_movies)\n",
    "tf_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:20.667210Z",
     "iopub.status.busy": "2025-02-11T07:03:20.666806Z",
     "iopub.status.idle": "2025-02-11T07:03:20.898952Z",
     "shell.execute_reply": "2025-02-11T07:03:20.897983Z",
     "shell.execute_reply.started": "2025-02-11T07:03:20.667180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(matrix):\n",
    "    _cosine = linear_kernel(matrix, matrix)\n",
    "    return _cosine\n",
    "cosine_matrix = cosine_similarity(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:21.265949Z",
     "iopub.status.busy": "2025-02-11T07:03:21.265593Z",
     "iopub.status.idle": "2025-02-11T07:03:21.271823Z",
     "shell.execute_reply": "2025-02-11T07:03:21.270981Z",
     "shell.execute_reply.started": "2025-02-11T07:03:21.265919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cosine_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Matrix Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:23.594314Z",
     "iopub.status.busy": "2025-02-11T07:03:23.593964Z",
     "iopub.status.idle": "2025-02-11T07:03:23.623154Z",
     "shell.execute_reply": "2025-02-11T07:03:23.621815Z",
     "shell.execute_reply.started": "2025-02-11T07:03:23.594287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ratings['movieId'] = ratings['movieId'].copy().map(movie_id_to_index)\n",
    "max_movie_id = ratings['movieId'].max()\n",
    "\n",
    "print(\"Maximum movieId in ratings dataframe:\", max_movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:24.002836Z",
     "iopub.status.busy": "2025-02-11T07:03:24.002492Z",
     "iopub.status.idle": "2025-02-11T07:03:24.264970Z",
     "shell.execute_reply": "2025-02-11T07:03:24.263771Z",
     "shell.execute_reply.started": "2025-02-11T07:03:24.002807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sorted_ratings = ratings.sort_values(by=['userId', 'timestamp'])\n",
    "sorted_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:25.947027Z",
     "iopub.status.busy": "2025-02-11T07:03:25.946662Z",
     "iopub.status.idle": "2025-02-11T07:03:28.248142Z",
     "shell.execute_reply": "2025-02-11T07:03:28.247332Z",
     "shell.execute_reply.started": "2025-02-11T07:03:25.946998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "transitions = defaultdict(int)\n",
    "for user, group in sorted_ratings.groupby('userId'):\n",
    "    movies = group['movieId'].tolist()\n",
    "    for i in range(len(movies) - 1):\n",
    "        transitions[(movies[i], movies[i + 1])] += 1\n",
    "\n",
    "transition_matrix = defaultdict(dict)\n",
    "movie_counts = defaultdict(int)\n",
    "\n",
    "for (movie_i, movie_j), count in transitions.items():\n",
    "    movie_counts[movie_i] += count\n",
    "\n",
    "for (movie_i, movie_j), count in transitions.items():\n",
    "    transition_matrix[movie_i][movie_j] = count / movie_counts[movie_i]\n",
    "\n",
    "unique_movies = sorted(set(sorted_ratings['movieId']))\n",
    "movie_to_idx = {movie: idx for idx, movie in enumerate(unique_movies)}\n",
    "n_movies = len(unique_movies)\n",
    "\n",
    "sequential_matrix = np.zeros((n_movies, n_movies))\n",
    "for movie_i, neighbors in transition_matrix.items():\n",
    "    for movie_j, prob in neighbors.items():\n",
    "        sequential_matrix[movie_to_idx[movie_i], movie_to_idx[movie_j]] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:28.249715Z",
     "iopub.status.busy": "2025-02-11T07:03:28.249356Z",
     "iopub.status.idle": "2025-02-11T07:03:28.255968Z",
     "shell.execute_reply": "2025-02-11T07:03:28.255071Z",
     "shell.execute_reply.started": "2025-02-11T07:03:28.249681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sequential_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of a sequence array for SASRec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:29.969574Z",
     "iopub.status.busy": "2025-02-11T07:03:29.969233Z",
     "iopub.status.idle": "2025-02-11T07:03:30.008925Z",
     "shell.execute_reply": "2025-02-11T07:03:30.007970Z",
     "shell.execute_reply.started": "2025-02-11T07:03:29.969545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filtered_ratings = sorted_ratings[['userId', 'movieId']].copy()\n",
    "filtered_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:31.795199Z",
     "iopub.status.busy": "2025-02-11T07:03:31.794815Z",
     "iopub.status.idle": "2025-02-11T07:03:31.802593Z",
     "shell.execute_reply": "2025-02-11T07:03:31.801767Z",
     "shell.execute_reply.started": "2025-02-11T07:03:31.795172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ratings_array = filtered_ratings.to_numpy(dtype=np.int32)\n",
    "ratings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:32.259320Z",
     "iopub.status.busy": "2025-02-11T07:03:32.258970Z",
     "iopub.status.idle": "2025-02-11T07:03:32.264669Z",
     "shell.execute_reply": "2025-02-11T07:03:32.263725Z",
     "shell.execute_reply.started": "2025-02-11T07:03:32.259294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ratings_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:33.947603Z",
     "iopub.status.busy": "2025-02-11T07:03:33.947277Z",
     "iopub.status.idle": "2025-02-11T07:03:33.967804Z",
     "shell.execute_reply": "2025-02-11T07:03:33.966985Z",
     "shell.execute_reply.started": "2025-02-11T07:03:33.947579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_users = filtered_ratings['userId'].nunique()\n",
    "num_items = filtered_ratings['movieId'].nunique()\n",
    "\n",
    "print(f\"Number of Users: {num_users}\")\n",
    "print(f\"Number of Items (Movies): {num_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Matrix Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:36.004758Z",
     "iopub.status.busy": "2025-02-11T07:03:36.004434Z",
     "iopub.status.idle": "2025-02-11T07:03:36.008890Z",
     "shell.execute_reply": "2025-02-11T07:03:36.007819Z",
     "shell.execute_reply.started": "2025-02-11T07:03:36.004735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:36.512222Z",
     "iopub.status.busy": "2025-02-11T07:03:36.511823Z",
     "iopub.status.idle": "2025-02-11T07:03:36.589072Z",
     "shell.execute_reply": "2025-02-11T07:03:36.588090Z",
     "shell.execute_reply.started": "2025-02-11T07:03:36.512195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hybrid_matrix = alpha * sequential_matrix + beta * cosine_matrix\n",
    "hybrid_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:37.074602Z",
     "iopub.status.busy": "2025-02-11T07:03:37.074243Z",
     "iopub.status.idle": "2025-02-11T07:03:37.110237Z",
     "shell.execute_reply": "2025-02-11T07:03:37.109258Z",
     "shell.execute_reply.started": "2025-02-11T07:03:37.074574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sparsity = (np.sum(hybrid_matrix == 0) / hybrid_matrix.size) * 100\n",
    "print(f\"Sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:39.136218Z",
     "iopub.status.busy": "2025-02-11T07:03:39.135860Z",
     "iopub.status.idle": "2025-02-11T07:03:42.762535Z",
     "shell.execute_reply": "2025-02-11T07:03:42.761427Z",
     "shell.execute_reply.started": "2025-02-11T07:03:39.136193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def normalize_adjacency(adj):\n",
    "    degree = torch.sum(adj, dim=1, keepdim=True)\n",
    "    degree_inv_sqrt = torch.pow(degree, -0.5)\n",
    "    adj_normalized = degree_inv_sqrt * adj * degree_inv_sqrt.t()\n",
    "    return adj_normalized\n",
    "\n",
    "def personalized_ppr(adj, alpha=0.1, max_iter=10, tol=1e-6):\n",
    "    num_nodes = adj.shape[0]\n",
    "    adj_norm = normalize_adjacency(adj)\n",
    "    ppr_matrix = torch.eye(num_nodes, device=adj.device)\n",
    "    for _ in range(max_iter):\n",
    "        new_ppr = alpha * torch.eye(num_nodes, device=adj.device) + (1 - alpha) * torch.mm(adj_norm, ppr_matrix)\n",
    "        if torch.norm(new_ppr - ppr_matrix) < tol:\n",
    "            break\n",
    "        ppr_matrix = new_ppr\n",
    "    \n",
    "    return ppr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:42.764251Z",
     "iopub.status.busy": "2025-02-11T07:03:42.763731Z",
     "iopub.status.idle": "2025-02-11T07:03:51.348168Z",
     "shell.execute_reply": "2025-02-11T07:03:51.347184Z",
     "shell.execute_reply.started": "2025-02-11T07:03:42.764224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "alpha_ppr = 0.1  # You can tune this value\n",
    "adj_matrix = torch.tensor(hybrid_matrix, dtype=torch.float32)\n",
    "adj_matrix = personalized_ppr(adj_matrix, alpha_ppr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:03:51.350249Z",
     "iopub.status.busy": "2025-02-11T07:03:51.349899Z",
     "iopub.status.idle": "2025-02-11T07:03:51.455361Z",
     "shell.execute_reply": "2025-02-11T07:03:51.454433Z",
     "shell.execute_reply.started": "2025-02-11T07:03:51.350222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_movies = adj_matrix.shape[0]\n",
    "padding_row = torch.zeros((1, num_movies))\n",
    "adj_matrix = torch.cat([adj_matrix, padding_row], dim=0)\n",
    "padding_col = torch.zeros((num_movies + 1, 1))\n",
    "adj_matrix = torch.cat([adj_matrix, padding_col], dim=1)\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:05:08.297047Z",
     "iopub.status.busy": "2025-02-11T07:05:08.296654Z",
     "iopub.status.idle": "2025-02-11T07:05:08.303157Z",
     "shell.execute_reply": "2025-02-11T07:05:08.302077Z",
     "shell.execute_reply.started": "2025-02-11T07:05:08.297016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, alpha=0.1):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        propagated = torch.mm(adj, x)\n",
    "        x = self.alpha * x + (1 - self.alpha) * propagated\n",
    "        x = self.linear(x)\n",
    "        return F.relu(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SASRec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:05:11.344009Z",
     "iopub.status.busy": "2025-02-11T07:05:11.343594Z",
     "iopub.status.idle": "2025-02-11T07:05:11.348466Z",
     "shell.execute_reply": "2025-02-11T07:05:11.347317Z",
     "shell.execute_reply.started": "2025-02-11T07:05:11.343974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Process, Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:05:11.946711Z",
     "iopub.status.busy": "2025-02-11T07:05:11.946360Z",
     "iopub.status.idle": "2025-02-11T07:05:11.961821Z",
     "shell.execute_reply": "2025-02-11T07:05:11.960894Z",
     "shell.execute_reply.started": "2025-02-11T07:05:11.946683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_index(ui_mat):\n",
    "    n_users = ui_mat[:,0].max()\n",
    "    n_items = ui_mat[:,1].max()\n",
    "\n",
    "    u2i_index = [[] for _ in range(n_users + 1)]\n",
    "    i2u_index = [[] for _ in range(n_items + 1)]\n",
    "\n",
    "    for ui_pair in ui_mat:\n",
    "        u2i_index[ui_pair[0]].append(ui_pair[1])\n",
    "        i2u_index[ui_pair[1]].append(ui_pair[0])\n",
    "\n",
    "    return u2i_index, i2u_index\n",
    "\n",
    "def random_neq(l, r, s):\n",
    "    t = np.random.randint(l, r)\n",
    "    while t in s:\n",
    "        t = np.random.randint(l, r)\n",
    "    return t\n",
    "\n",
    "def sample_function(user_train, usernum, itemnum, batch_size, maxlen, result_queue, SEED):\n",
    "    def sample(uid):\n",
    "        while len(user_train[uid]) <= 1: uid = np.random.randint(1, usernum + 1)\n",
    "\n",
    "        seq = np.zeros([maxlen], dtype=np.int32)\n",
    "        pos = np.zeros([maxlen], dtype=np.int32)\n",
    "        neg = np.zeros([maxlen], dtype=np.int32)\n",
    "        nxt = user_train[uid][-1]\n",
    "        idx = maxlen - 1\n",
    "\n",
    "        ts = set(user_train[uid])\n",
    "        for i in reversed(user_train[uid][:-1]):\n",
    "            seq[idx] = i\n",
    "            pos[idx] = nxt\n",
    "            if nxt != 0: neg[idx] = random_neq(1, itemnum + 1, ts)\n",
    "            nxt = i\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "\n",
    "        return (uid, seq, pos, neg)\n",
    "\n",
    "    np.random.seed(SEED)\n",
    "    uids = np.arange(1, usernum+1, dtype=np.int32)\n",
    "    counter = 0\n",
    "    while True:\n",
    "        if counter % usernum == 0:\n",
    "            np.random.shuffle(uids)\n",
    "        one_batch = []\n",
    "        for i in range(batch_size):\n",
    "            one_batch.append(sample(uids[counter % usernum]))\n",
    "            counter += 1\n",
    "        result_queue.put(zip(*one_batch))\n",
    "\n",
    "\n",
    "class WarpSampler(object):\n",
    "    def __init__(self, User, usernum, itemnum, batch_size=64, maxlen=10, n_workers=1):\n",
    "        self.result_queue = Queue(maxsize=n_workers * 10)\n",
    "        self.processors = []\n",
    "        for i in range(n_workers):\n",
    "            self.processors.append(\n",
    "                Process(target=sample_function, args=(User,\n",
    "                                                      usernum,\n",
    "                                                      itemnum,\n",
    "                                                      batch_size,\n",
    "                                                      maxlen,\n",
    "                                                      self.result_queue,\n",
    "                                                      np.random.randint(2e9)\n",
    "                                                      )))\n",
    "            self.processors[-1].daemon = True\n",
    "            self.processors[-1].start()\n",
    "\n",
    "    def next_batch(self):\n",
    "        return self.result_queue.get()\n",
    "\n",
    "    def close(self):\n",
    "        for p in self.processors:\n",
    "            p.terminate()\n",
    "            p.join()\n",
    "\n",
    "\n",
    "def data_partition(df):\n",
    "    usernum = 0\n",
    "    itemnum = 0\n",
    "    User = defaultdict(list)\n",
    "    user_train = {}\n",
    "    user_valid = {}\n",
    "    user_test = {}\n",
    "    for index, row in df.iterrows():\n",
    "        u = row[0]  \n",
    "        i = row[1]  \n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        usernum = max(u, usernum)\n",
    "        itemnum = max(i, itemnum)\n",
    "        User[u].append(i)\n",
    "\n",
    "    for user in User:\n",
    "        nfeedback = len(User[user])\n",
    "        if nfeedback < 3:\n",
    "            user_train[user] = User[user]\n",
    "            user_valid[user] = []\n",
    "            user_test[user] = []\n",
    "        else:\n",
    "            user_train[user] = User[user][:-2]\n",
    "            user_valid[user] = []\n",
    "            user_valid[user].append(User[user][-2])\n",
    "            user_test[user] = []\n",
    "            user_test[user].append(User[user][-1])\n",
    "    return [user_train, user_valid, user_test, usernum, itemnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:05:15.391339Z",
     "iopub.status.busy": "2025-02-11T07:05:15.390969Z",
     "iopub.status.idle": "2025-02-11T07:05:15.404621Z",
     "shell.execute_reply": "2025-02-11T07:05:15.403649Z",
     "shell.execute_reply.started": "2025-02-11T07:05:15.391310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "\n",
    "    NDCG = 0.0\n",
    "    HT = 0.0\n",
    "    MRR = 0.0\n",
    "    valid_user = 0.0\n",
    "\n",
    "    if usernum > 10000:\n",
    "        users = random.sample(range(1, usernum + 1), 10000)\n",
    "    else:\n",
    "        users = range(1, usernum + 1)\n",
    "    \n",
    "    for u in users:\n",
    "        if len(train[u]) < 1 or len(test[u]) < 1: continue\n",
    "\n",
    "        seq = np.zeros([args['maxlen']], dtype=np.int32)\n",
    "        idx = args['maxlen'] - 1\n",
    "        seq[idx] = valid[u][0]\n",
    "        idx -= 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        item_idx = [test[u][0]]\n",
    "        for _ in range(100):\n",
    "            t = np.random.randint(1, itemnum + 1)\n",
    "            while t in rated: t = np.random.randint(1, itemnum + 1)\n",
    "            item_idx.append(t)\n",
    "\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n",
    "        predictions = predictions[0]  \n",
    "\n",
    "        rank = predictions.argsort().argsort()[0].item()\n",
    "\n",
    "        valid_user += 1\n",
    "\n",
    "        if rank < 10:\n",
    "            NDCG += 1 / np.log2(rank + 2)\n",
    "            HT += 1\n",
    "            MRR += 1 / (rank + 1)  \n",
    "\n",
    "    return NDCG / valid_user, HT / valid_user, MRR / valid_user\n",
    "\n",
    "\n",
    "def evaluate_valid(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "\n",
    "    NDCG = 0.0\n",
    "    HT = 0.0\n",
    "    MRR = 0.0 \n",
    "    valid_user = 0.0\n",
    "    if usernum > 10000:\n",
    "        users = random.sample(range(1, usernum + 1), 10000)\n",
    "    else:\n",
    "        users = range(1, usernum + 1)\n",
    "    \n",
    "    for u in users:\n",
    "        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n",
    "\n",
    "        seq = np.zeros([args['maxlen']], dtype=np.int32)\n",
    "        idx = args['maxlen'] - 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        item_idx = [valid[u][0]]\n",
    "        for _ in range(100):\n",
    "            t = np.random.randint(1, itemnum + 1)\n",
    "            while t in rated: t = np.random.randint(1, itemnum + 1)\n",
    "            item_idx.append(t)\n",
    "\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n",
    "        predictions = predictions[0]\n",
    "\n",
    "        rank = predictions.argsort().argsort()[0].item()\n",
    "\n",
    "        valid_user += 1\n",
    "\n",
    "        if rank < 10:\n",
    "            NDCG += 1 / np.log2(rank + 2)\n",
    "            HT += 1\n",
    "            MRR += 1 / (rank + 1)\n",
    "\n",
    "    return NDCG / valid_user, HT / valid_user, MRR / valid_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:05:18.445615Z",
     "iopub.status.busy": "2025-02-11T07:05:18.445249Z",
     "iopub.status.idle": "2025-02-11T07:05:18.462920Z",
     "shell.execute_reply": "2025-02-11T07:05:18.461967Z",
     "shell.execute_reply.started": "2025-02-11T07:05:18.445586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PointWiseFeedForward(torch.nn.Module):\n",
    "    def __init__(self, hidden_units, dropout_rate):\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n",
    "        outputs = outputs.transpose(-1, -2) \n",
    "        outputs += inputs\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class SASRec(torch.nn.Module):\n",
    "    def __init__(self, user_num, item_num, args, adj_matrix):\n",
    "        super(SASRec, self).__init__()\n",
    "\n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "        self.dev = args['device']\n",
    "\n",
    "        self.gcn_layers = nn.ModuleList([\n",
    "            GCNLayer(args['hidden_units'], args['hidden_units']) \n",
    "            for _ in range(args['num_gcn_layers'])\n",
    "        ])\n",
    "\n",
    "        self.adj_matrix = adj_matrix\n",
    "        self.item_emb = torch.nn.Embedding(item_num + 1, args['hidden_units'], padding_idx=0)\n",
    "\n",
    "        self.layer_agg = None\n",
    "        \n",
    "        self.pos_emb = torch.nn.Embedding(args['maxlen']+1, args['hidden_units'], padding_idx=0)\n",
    "        self.emb_dropout = torch.nn.Dropout(p=args['dropout_rate'])\n",
    "\n",
    "        self.attention_layernorms = torch.nn.ModuleList() \n",
    "        self.attention_layers = torch.nn.ModuleList()\n",
    "        self.forward_layernorms = torch.nn.ModuleList()\n",
    "        self.forward_layers = torch.nn.ModuleList()\n",
    "\n",
    "        self.last_layernorm = torch.nn.LayerNorm(args['hidden_units'], eps=1e-8)\n",
    "\n",
    "        for _ in range(args['num_blocks']):\n",
    "            new_attn_layernorm = torch.nn.LayerNorm(args['hidden_units'], eps=1e-8)\n",
    "            self.attention_layernorms.append(new_attn_layernorm)\n",
    "\n",
    "            new_attn_layer = torch.nn.MultiheadAttention(args['hidden_units'],\n",
    "                                                          args['num_heads'],\n",
    "                                                          args['dropout_rate'])\n",
    "            self.attention_layers.append(new_attn_layer)\n",
    "\n",
    "            new_fwd_layernorm = torch.nn.LayerNorm(args['hidden_units'], eps=1e-8)\n",
    "            self.forward_layernorms.append(new_fwd_layernorm)\n",
    "\n",
    "            new_fwd_layer = PointWiseFeedForward(args['hidden_units'], args['dropout_rate'])\n",
    "            self.forward_layers.append(new_fwd_layer)\n",
    "            \n",
    "    def get_graph_embeddings(self):\n",
    "        layer_output = F.embedding(torch.arange(self.item_num+1, device=self.dev), self.item_emb.weight)\n",
    "\n",
    "        for gcn_layer in self.gcn_layers:\n",
    "            layer_output = gcn_layer(layer_output, self.adj_matrix)\n",
    "\n",
    "        return layer_output\n",
    "        \n",
    "        \n",
    "    def log2feats(self, log_seqs):\n",
    "\n",
    "        item_embeddings = self.get_graph_embeddings()\n",
    "        seqs = F.embedding(torch.LongTensor(log_seqs).to(self.dev), item_embeddings)\n",
    "        \n",
    "        seqs *= self.item_emb.embedding_dim ** 0.5\n",
    "        poss = np.tile(np.arange(1, log_seqs.shape[1] + 1), [log_seqs.shape[0], 1])\n",
    "        poss *= (log_seqs != 0)\n",
    "        seqs += self.pos_emb(torch.LongTensor(poss).to(self.dev))\n",
    "        seqs = self.emb_dropout(seqs)\n",
    "\n",
    "        tl = seqs.shape[1] \n",
    "        attention_mask = ~torch.tril(torch.ones((tl, tl), dtype=torch.bool, device=self.dev))\n",
    "\n",
    "        for i in range(len(self.attention_layers)):\n",
    "            seqs = torch.transpose(seqs, 0, 1)\n",
    "            Q = self.attention_layernorms[i](seqs)\n",
    "            mha_outputs, _ = self.attention_layers[i](Q, seqs, seqs,\n",
    "                                                      attn_mask=attention_mask)\n",
    "            seqs = Q + mha_outputs\n",
    "            seqs = torch.transpose(seqs, 0, 1)\n",
    "\n",
    "            seqs = self.forward_layernorms[i](seqs)\n",
    "            seqs = self.forward_layers[i](seqs)\n",
    "\n",
    "        log_feats = self.last_layernorm(seqs)\n",
    "\n",
    "        return log_feats\n",
    "\n",
    "    def forward(self, user_ids, log_seqs, pos_seqs, neg_seqs):\n",
    "        log_feats = self.log2feats(log_seqs)\n",
    "\n",
    "        item_embeddings = self.get_graph_embeddings()\n",
    "        pos_embs = self.item_emb(torch.LongTensor(pos_seqs).to(self.dev))\n",
    "        neg_embs = self.item_emb(torch.LongTensor(neg_seqs).to(self.dev))\n",
    "\n",
    "        pos_logits = (log_feats * pos_embs).sum(dim=-1)\n",
    "        neg_logits = (log_feats * neg_embs).sum(dim=-1)\n",
    "\n",
    "        return pos_logits, neg_logits \n",
    "\n",
    "    def predict(self, user_ids, log_seqs, item_indices): \n",
    "        log_feats = self.log2feats(log_seqs)\n",
    "\n",
    "        final_feat = log_feats[:, -1, :] \n",
    "\n",
    "        item_embs = self.item_emb(torch.LongTensor(item_indices).to(self.dev))\n",
    "        logits = item_embs.matmul(final_feat.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:05:22.131620Z",
     "iopub.status.busy": "2025-02-11T07:05:22.131138Z",
     "iopub.status.idle": "2025-02-11T07:06:23.688771Z",
     "shell.execute_reply": "2025-02-11T07:06:23.687969Z",
     "shell.execute_reply.started": "2025-02-11T07:05:22.131581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "u2i_index, i2u_index = build_index(ratings_array)\n",
    "dataset = data_partition(filtered_ratings)\n",
    "[user_train, user_valid, user_test, usernum, itemnum] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:06:23.690063Z",
     "iopub.status.busy": "2025-02-11T07:06:23.689789Z",
     "iopub.status.idle": "2025-02-11T07:06:23.694887Z",
     "shell.execute_reply": "2025-02-11T07:06:23.693860Z",
     "shell.execute_reply.started": "2025-02-11T07:06:23.690040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(usernum, itemnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:06:23.696593Z",
     "iopub.status.busy": "2025-02-11T07:06:23.696334Z",
     "iopub.status.idle": "2025-02-11T07:06:23.715905Z",
     "shell.execute_reply": "2025-02-11T07:06:23.714939Z",
     "shell.execute_reply.started": "2025-02-11T07:06:23.696571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'batch_size': 128,\n",
    "    'lr': 0.001,\n",
    "    'maxlen': 50,\n",
    "    'hidden_units': 50,\n",
    "    'num_blocks': 2,\n",
    "    'num_epochs': 200,\n",
    "    'num_heads': 1,\n",
    "    'dropout_rate': 0.2,\n",
    "    'l2_emb': 0.0,\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'inference_only': False,\n",
    "    'num_gcn_layers': 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:06:23.717188Z",
     "iopub.status.busy": "2025-02-11T07:06:23.716910Z",
     "iopub.status.idle": "2025-02-11T07:06:23.738513Z",
     "shell.execute_reply": "2025-02-11T07:06:23.737597Z",
     "shell.execute_reply.started": "2025-02-11T07:06:23.717164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_batch = (len(user_train) - 1) // args['batch_size'] + 1\n",
    "cc = 0.0\n",
    "for u in user_train:\n",
    "    cc += len(user_train[u])\n",
    "print('Average sequence length: %.2f' % (cc / len(user_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:06:23.739939Z",
     "iopub.status.busy": "2025-02-11T07:06:23.739566Z",
     "iopub.status.idle": "2025-02-11T07:06:23.856530Z",
     "shell.execute_reply": "2025-02-11T07:06:23.854957Z",
     "shell.execute_reply.started": "2025-02-11T07:06:23.739904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sampler = WarpSampler(user_train, usernum, itemnum, batch_size=args['batch_size'], maxlen=args['maxlen'], n_workers=3)\n",
    "model = SASRec(usernum, itemnum, args, adj_matrix).to(args['device'])\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "        try:\n",
    "            torch.nn.init.xavier_normal_(param.data)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "model.pos_emb.weight.data[0, :] = 0\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T07:06:23.858983Z",
     "iopub.status.busy": "2025-02-11T07:06:23.858534Z",
     "iopub.status.idle": "2025-02-11T08:05:17.434306Z",
     "shell.execute_reply": "2025-02-11T08:05:17.433303Z",
     "shell.execute_reply.started": "2025-02-11T07:06:23.858928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "adam_optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], betas=(0.9, 0.98), weight_decay=1e-4)\n",
    "\n",
    "best_val_ndcg, best_val_hr, best_val_mrr = 0.0, 0.0, 0.0\n",
    "best_test_ndcg, best_test_hr, best_test_mrr = 0.0, 0.0, 0.0\n",
    "T = 0.0\n",
    "t0 = time.time()\n",
    "\n",
    "patience = 5\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "losses = []\n",
    "ndcgs = []\n",
    "hrs = []\n",
    "mrrs = []\n",
    "\n",
    "for epoch in range(1, args['num_epochs'] + 1):\n",
    "    for step in range(num_batch):  \n",
    "        u, seq, pos, neg = sampler.next_batch() \n",
    "        u, seq, pos, neg = np.array(u), np.array(seq), np.array(pos), np.array(neg)\n",
    "        pos_logits, neg_logits = model(u, seq, pos, neg)\n",
    "        pos_labels, neg_labels = torch.ones(pos_logits.shape, device=args['device']), torch.zeros(neg_logits.shape, device=args['device'])\n",
    "        adam_optimizer.zero_grad()\n",
    "        indices = np.where(pos != 0)\n",
    "        loss = bce_criterion(pos_logits[indices], pos_labels[indices])\n",
    "        loss += bce_criterion(neg_logits[indices], neg_labels[indices])\n",
    "        for param in model.item_emb.parameters(): loss += args['l2_emb'] * torch.norm(param)\n",
    "        loss.backward()\n",
    "        adam_optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())  \n",
    "    print(f\"Loss in epoch {epoch} iteration {step}: {loss.item()}\")\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        model.eval()\n",
    "        t1 = time.time() - t0\n",
    "        T += t1\n",
    "        print('Evaluating', end='')\n",
    "        \n",
    "        t_test = evaluate(model, dataset, args)\n",
    "        t_valid = evaluate_valid(model, dataset, args)\n",
    "        \n",
    "        print(f'epoch:{epoch}, time: {T:.6f}(s), valid (NDCG@10: {t_valid[0]:.4f}, HR@10: {t_valid[1]:.4f}, MRR: {t_valid[2]:.4f}), '\n",
    "              f'test (NDCG@10: {t_test[0]:.4f}, HR@10: {t_test[1]:.4f}, MRR: {t_test[2]:.4f})')\n",
    "\n",
    "        ndcgs.append(t_valid[0])\n",
    "        hrs.append(t_valid[1])\n",
    "        mrrs.append(t_valid[2])\n",
    "    \n",
    "        if (t_valid[0] > best_val_ndcg or t_valid[1] > best_val_hr or t_valid[2] > best_val_mrr or\n",
    "            t_test[0] > best_test_ndcg or t_test[1] > best_test_hr or t_test[2] > best_test_mrr):\n",
    "            \n",
    "            best_val_ndcg = max(t_valid[0], best_val_ndcg)\n",
    "            best_val_hr = max(t_valid[1], best_val_hr)\n",
    "            best_val_mrr = max(t_valid[2], best_val_mrr)\n",
    "            best_test_ndcg = max(t_test[0], best_test_ndcg)\n",
    "            best_test_hr = max(t_test[1], best_test_hr)\n",
    "            best_test_mrr = max(t_test[2], best_test_mrr)\n",
    "            \n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "    \n",
    "        if no_improvement_epochs >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}. No improvement in validation NDCG/HR/MRR for {patience} epochs.\")\n",
    "            break\n",
    "    \n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "ax[0, 0].plot(range(1, len(losses) + 1), losses, label='Loss', color='red')\n",
    "ax[0, 0].set_xlabel('Epoch')\n",
    "ax[0, 0].set_ylabel('Loss')\n",
    "ax[0, 0].set_title('Loss vs Epoch')\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "ax[0, 1].plot(range(20, len(ndcgs) * 20 + 1, 20), ndcgs, label='NDCG@10', color='blue')\n",
    "ax[0, 1].set_xlabel('Epoch')\n",
    "ax[0, 1].set_ylabel('NDCG@10')\n",
    "ax[0, 1].set_title('NDCG@10 vs Epoch')\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "ax[1, 0].plot(range(20, len(hrs) * 20 + 1, 20), hrs, label='HR@10', color='green')\n",
    "ax[1, 0].set_xlabel('Epoch')\n",
    "ax[1, 0].set_ylabel('HR@10')\n",
    "ax[1, 0].set_title('HR@10 vs Epoch')\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "ax[1, 1].plot(range(20, len(mrrs) * 20 + 1, 20), mrrs, label='MRR', color='purple')\n",
    "ax[1, 1].set_xlabel('Epoch')\n",
    "ax[1, 1].set_ylabel('MRR')\n",
    "ax[1, 1].set_title('MRR vs Epoch')\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Best Validation Metrics: '\n",
    "      f'NDCG@10: {best_val_ndcg:.4f}, HR@10: {best_val_hr:.4f}, MRR: {best_val_mrr:.4f}')\n",
    "print(f'Best Test Metrics: '\n",
    "      f'NDCG@10: {best_test_ndcg:.4f}, HR@10: {best_test_hr:.4f}, MRR: {best_test_mrr:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sampler.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4004281,
     "sourceId": 6969416,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
